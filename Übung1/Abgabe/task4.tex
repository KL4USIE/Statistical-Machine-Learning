\exercise{Information Theory}
\begin{questions}
	
	%----------------------------------------------
	\begin{question}{Entropy}{5}		
	\begin{answer} 
			\begin{enumerate}
		\item \begin{equation}
 - 0,04 * {\log_2 0,04}  - 0,22 * {\log_2 0,22} - 0,67 * {\log_2 0,67} - 0,07 * {\log_2 0,07} = 1,3219   
\end{equation}
An average of 1 bit can be transmitted.
		\item 
		\begin{equation}
		H = ln(4) = 1,386 \approx 2
		\end{equation}
		Maxmimum of 2 bits per symbol can be transmitted using a set of four symbols. 
		The distribution over the symbols requires that  at least the maximum is as great as that of all other members.
		\end{enumerate}
		
	\end{answer}
		
	\end{question}
	
\end{questions}

